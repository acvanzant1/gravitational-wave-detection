{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "########### IMPORTS ############\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycbc import distributions\n",
    "from pycbc.waveform import get_td_waveform, td_approximants\n",
    "from pycbc.detector import Detector\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gwpy\n",
    "import pylab\n",
    "from tqdm.notebook import tqdm\n",
    "from gwpy.timeseries import TimeSeries\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import pycbc.noise\n",
    "import pycbc.psd\n",
    "from pycbc.filter import matched_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Binary Mass Distributions for BBH\n",
      "Generated Binary Mass Distributions for BNS\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Binary Mass Distributions for BBH\")\n",
    "bbh_two_mass_distributions = distributions.Uniform(mass1=(10, 50),\n",
    "                                               mass2=(10, 50))\n",
    "\n",
    "bbh_two_mass_samples = bbh_two_mass_distributions.rvs(size=1000)\n",
    "\n",
    "print(\"Generated Binary Mass Distributions for BNS\")\n",
    "bns_two_mass_distributions = distributions.Uniform(mass1=(1, 2),\n",
    "                                               mass2=(1, 2))\n",
    "\n",
    "bns_two_mass_samples = bns_two_mass_distributions.rvs(size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289ca2cd01ea42a09435921ee87b8df5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(range(1000)):\n",
    "    \n",
    "    # The color of the noise matches a PSD which you provide\n",
    "    flow = 30.0\n",
    "    delta_f = 1.0 / 16\n",
    "    flen = int(2048 / delta_f) + 1\n",
    "    psd = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, flow)\n",
    "\n",
    "    # Generate 4 seconds of noise at 4096 Hz\n",
    "    delta_t = 1.0 / 4096\n",
    "    tsamples = int(4 / delta_t)\n",
    "    noise = pycbc.noise.noise_from_psd(tsamples, delta_t, psd)\n",
    "\n",
    "    noise *= 1e21\n",
    "    noise *= 0.4\n",
    "    noise = TimeSeries.from_pycbc(noise)\n",
    "\n",
    "    noise *= 1e-17\n",
    "    noise.write(\"Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/noise_templates/noise_4k_\"+str(i)+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7f856819d245d8a18642dd9320128e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_times_bbh = [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5]\n",
    "start_times_bns = [0, 0.5, 1, 1.5, 2, 2.5, 3]\n",
    "\n",
    "for i in tqdm(range(len(bbh_two_mass_samples))):\n",
    "\n",
    "    hp1, hc1 = get_td_waveform(approximant=\"SEOBNRv2\",                                \n",
    "                         mass1=bbh_two_mass_samples[i][0],\n",
    "                         mass2=bbh_two_mass_samples[i][1],\n",
    "                         delta_t=1.0/4096,\n",
    "                         f_lower=40)\n",
    "\n",
    "\n",
    "    hp2, hc2 = get_td_waveform(approximant=\"IMRPhenomPv2_NRTidal\", \n",
    "                         mass1=bns_two_mass_samples[i][0],\n",
    "                         mass2=bns_two_mass_samples[i][1],\n",
    "                         delta_t=1.0/4096,\n",
    "                         f_lower=40)\n",
    "\n",
    "\n",
    "    bbh_signal = TimeSeries.from_pycbc(hp1)\n",
    "    st1 = np.random.randint(0, 8)\n",
    "    bbh_signal.t0 = start_times_bbh[st1]\n",
    "    bbh_signal = (bbh_signal/(max(bbh_signal.max(), np.abs(bbh_signal.min()))))*0.2\n",
    "\n",
    "\n",
    "    # Extract the last 1 sec from the BNS signal\n",
    "    t = hp2.get_end_time()\n",
    "    hp2 = hp2.time_slice(t-1, t)\n",
    "\n",
    "    bns_signal = TimeSeries.from_pycbc(hp2)\n",
    "    st2 = np.random.randint(0, 7)\n",
    "    bns_signal.t0 = start_times_bns[st2]\n",
    "    bns_signal = bns_signal.taper()\n",
    "    bns_signal = (bns_signal/(max(bns_signal.max(), np.abs(bns_signal.min()))))*0.2\n",
    "\n",
    "    # The color of the noise matches a PSD which you provide\n",
    "    flow = 30.0\n",
    "    delta_f = 1.0 / 16\n",
    "    flen = int(2048 / delta_f) + 1\n",
    "    psd = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, flow)\n",
    "\n",
    "    # Generate 4 seconds of noise at 4096 Hz\n",
    "    delta_t = 1.0 / 4096\n",
    "    tsamples = int(4 / delta_t)\n",
    "    noise = pycbc.noise.noise_from_psd(tsamples, delta_t, psd)\n",
    "\n",
    "    noise *= 1e21\n",
    "    noise *= 0.4\n",
    "    noise = TimeSeries.from_pycbc(noise)\n",
    "\n",
    "\n",
    "    data1 = noise.inject(bbh_signal)\n",
    "    data2 = noise.inject(bns_signal)\n",
    "\n",
    "    data1 *= 1e-17\n",
    "    data2 *= 1e-17\n",
    "    \n",
    "data1.write(\"Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/merged_bbh_noise_signal/merged_noise_signal_\"+str(i)+\".txt\")\n",
    "data2.write(\"Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/merged_bns_noise_signal/bns_merged_noise_signal_\"+str(i)+\".txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Alternate\n",
    "\n",
    "# # Not needed since the above method worked.\n",
    "# start_times_bbh = [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5]\n",
    "# start_times_bns = [0, 0.5, 1, 1.5, 2, 2.5, 3]\n",
    "\n",
    "# for i in tqdm(range(1000)):\n",
    "\n",
    "#     bbh_signal = TimeSeries.read(\" Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/bbh_signal/bbh_4k_\"+str(i)+\".txt\")\n",
    "#     st1 = np.random.randint(0, 8)\n",
    "#     bbh_signal.t0 = start_times_bbh[st1]\n",
    "#     bbh_signal = (bbh_signal/(max(bbh_signal.max(), np.abs(bbh_signal.min()))))*0.2\n",
    "\n",
    "#     bns_signal = TimeSeries.read(\" Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/bns_signal/bns_signal_\"+str(i)+\".txt\")\n",
    "#     st2 = np.random.randint(0, 7)\n",
    "#     bns_signal.t0 = start_times_bns[st2]\n",
    "#     bns_signal = bns_signal.taper()\n",
    "#     bns_signal = (bns_signal/(max(bns_signal.max(), np.abs(bns_signal.min()))))*0.2\n",
    "\n",
    "#     # The color of the noise matches a PSD which you provide\n",
    "#     flow = 30.0\n",
    "#     delta_f = 1.0 / 16\n",
    "#     flen = int(2048 / delta_f) + 1\n",
    "#     psd = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, flow)\n",
    "\n",
    "#     # Generate 4 seconds of noise at 4096 Hz\n",
    "#     delta_t = 1.0 / 4096\n",
    "#     tsamples = int(4 / delta_t)\n",
    "#     noise = pycbc.noise.noise_from_psd(tsamples, delta_t, psd)\n",
    "\n",
    "#     noise *= 1e21\n",
    "#     noise *= 0.4\n",
    "#     noise = TimeSeries.from_pycbc(noise)\n",
    "\n",
    "#     data1 = noise.inject(bbh_signal)\n",
    "#     data2 = noise.inject(bns_signal)\n",
    "\n",
    "#     data1 *= 1e-17\n",
    "#     data2 *= 1e-17\n",
    "\n",
    "#     data1.write(\" Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/merged_bbh_noise_signal/merged_noise_signal_\"+str(i)+\".txt\")\n",
    "#     data2.write(\" Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/merged_bns_noise_signal/bns_merged_noise_signal_\"+str(i)+\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:32<00:00, 60.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merging complete. Output saved to: /Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/val_Final_BBH_Merged_Noise_Signal_Reduced_No_ABS.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Merging BBH Noise + Signal Templates into single csv file\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define directory path\n",
    "path = \"Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/merged_bbh_noise_signal/\"\n",
    "output_file = \" Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/val_Final_BBH_Merged_Noise_Signal_Reduced_No_ABS.csv\"\n",
    "\n",
    "# Ensure output file is not a directory\n",
    "if os.path.isdir(output_file):\n",
    "    raise IsADirectoryError(f\"Expected a file, but found a directory: {output_file}\")\n",
    "\n",
    "# Get only valid data files, ignoring hidden files like .DS_Store\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and not f.startswith('.')]\n",
    "\n",
    "# Open the output CSV file\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    cw = csv.writer(f)\n",
    "\n",
    "    # Iterate through each file\n",
    "    for i in tqdm(files):\n",
    "        file_path = os.path.join(path, i)  # Ensure proper file path\n",
    "        \n",
    "        try:\n",
    "            # Attempt to read using UTF-8 encoding first\n",
    "            df = pd.read_csv(file_path, sep=' ', header=None, encoding='utf-8', engine='c')\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                # Try ISO-8859-1 if UTF-8 fails\n",
    "                df = pd.read_csv(file_path, sep=' ', header=None, encoding='ISO-8859-1', engine='c')\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading {file_path}: {e}\")\n",
    "                continue  # Skip file if all attempts fail\n",
    "        \n",
    "        # Ensure at least 2 columns exist before writing\n",
    "        if df.shape[1] > 1:\n",
    "            c = df.iloc[:, 1]  # Select the second column correctly\n",
    "            cw.writerow(c)\n",
    "\n",
    "print(f\"✅ Merging complete. Output saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:16<00:00, 61.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merging complete. Output saved to: /Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/val_Final_Merged_Noise_Reduced_No_Abs.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Merging Noise Templates into single csv file\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "path_1 = \" Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/noise_templates/\"\n",
    "output_file = \" Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/val_Final_Merged_Noise_Reduced_No_Abs.csv\"\n",
    "\n",
    "# Ensure output file is not a directory\n",
    "if os.path.isdir(output_file):\n",
    "    raise IsADirectoryError(f\"Expected a file, but found a directory: {output_file}\")\n",
    "\n",
    "# Get only valid files (ignores hidden/system files like .DS_Store)\n",
    "files_1 = [f for f in os.listdir(path_1) if os.path.isfile(os.path.join(path_1, f)) and not f.startswith('.')]\n",
    "\n",
    "# Open the output CSV file safely\n",
    "with open(output_file, 'w', newline='') as f1:\n",
    "    cw_1 = csv.writer(f1)\n",
    "\n",
    "    # Process each file\n",
    "    for i in tqdm(files_1):\n",
    "        file_path = os.path.join(path_1, i)  # Ensure proper path formatting\n",
    "\n",
    "        try:\n",
    "            # Attempt to read using UTF-8 encoding first\n",
    "            df = pd.read_csv(file_path, sep=' ', header=None, encoding=\"utf-8\", engine=\"c\")\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                # If UTF-8 fails, try ISO-8859-1 as fallback\n",
    "                df = pd.read_csv(file_path, sep=' ', header=None, encoding=\"ISO-8859-1\", engine=\"c\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading {file_path}: {e}\")\n",
    "                continue  # Skip this file if all attempts fail\n",
    "\n",
    "        # Ensure at least 2 columns exist before writing\n",
    "        if df.shape[1] > 1:\n",
    "            c = df.iloc[:, 1]  # Select second column\n",
    "            cw_1.writerow(c)\n",
    "\n",
    "print(f\"✅ Merging complete. Output saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:16<00:00, 62.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Merging complete. Output saved to: /Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/val_Final_BNS_Merged_Noise_Signal_Reduced_No_ABS.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Merging BNS Noise + Signal Templates into single csv file\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define paths\n",
    "path = \" Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/merged_bns_noise_signal/\"\n",
    "output_file = \"Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/val_Final_BNS_Merged_Noise_Signal_Reduced_No_ABS.csv\"\n",
    "\n",
    "# Ensure the output file is not a directory\n",
    "if os.path.isdir(output_file):\n",
    "    raise IsADirectoryError(f\"Expected a file, but found a directory: {output_file}\")\n",
    "\n",
    "# Get only valid files (ignores hidden/system files like .DS_Store)\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(os.path.join(path, f)) and not f.startswith('.')]\n",
    "\n",
    "# Open the output CSV file safely\n",
    "with open(output_file, 'w', newline='') as f:\n",
    "    cw = csv.writer(f)\n",
    "\n",
    "    # Process each file\n",
    "    for i in tqdm(files):\n",
    "        file_path = os.path.join(path, i)  # Ensure correct path\n",
    "\n",
    "        try:\n",
    "            # Try reading using UTF-8 first\n",
    "            df = pd.read_csv(file_path, sep=' ', header=None, encoding=\"utf-8\", engine=\"c\")\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                # If UTF-8 fails, try ISO-8859-1\n",
    "                df = pd.read_csv(file_path, sep=' ', header=None, encoding=\"ISO-8859-1\", engine=\"c\")\n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error reading {file_path}: {e}\")\n",
    "                continue  # Skip this file if all attempts fail\n",
    "\n",
    "        # Ensure at least 2 columns exist before writing\n",
    "        if df.shape[1] > 1:\n",
    "            c = df.iloc[:, 1]  # Select second column\n",
    "            cw.writerow(c)\n",
    "\n",
    "print(f\"✅ Merging complete. Output saved to: {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gw_env_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
