{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "########### IMPORTS ############\n",
    "################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adamvanzant/.pyenv/versions/gw_env_39/lib/python3.9/site-packages/pycbc/types/array.py:36: UserWarning: Wswiglal-redir-stdio:\n",
      "\n",
      "SWIGLAL standard output/error redirection is enabled in IPython.\n",
      "This may lead to performance penalties. To disable locally, use:\n",
      "\n",
      "with lal.no_swig_redirect_standard_output_error():\n",
      "    ...\n",
      "\n",
      "To disable globally, use:\n",
      "\n",
      "lal.swig_redirect_standard_output_error(False)\n",
      "\n",
      "Note however that this will likely lead to error messages from\n",
      "LAL functions being either misdirected or lost when called from\n",
      "Jupyter notebooks.\n",
      "\n",
      "To suppress this warning, use:\n",
      "\n",
      "import warnings\n",
      "warnings.filterwarnings(\"ignore\", \"Wswiglal-redir-stdio\")\n",
      "import lal\n",
      "\n",
      "  import lal as _lal\n"
     ]
    }
   ],
   "source": [
    "from pycbc import distributions\n",
    "from pycbc.waveform import get_td_waveform, td_approximants\n",
    "from pycbc.detector import Detector\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gwpy\n",
    "import pylab\n",
    "from tqdm.notebook import tqdm\n",
    "from gwpy.timeseries import TimeSeries\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import pycbc.noise\n",
    "import pycbc.psd\n",
    "from pycbc.filter import matched_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_params = 2\n",
    "directory = \"/Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/LIGO-Detector-Data/raw_val_data_files/Parameter-Estimation/\"+str(no_of_params)+\"_parameters/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "########### BBH Data Generation ############\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Binary Mass Distributions for BBH\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Binary Mass Distributions for BBH\")\n",
    "bbh_two_mass_distributions = distributions.Uniform(mass1=(10, 50),\n",
    "                                               mass2=(10, 50))\n",
    "\n",
    "bbh_two_mass_samples = bbh_two_mass_distributions.rvs(size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dd89587ebff43189618266cfc706281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "start_times_bbh = [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5]\n",
    "bbh_data_targets = np.zeros((len(bbh_two_mass_samples), no_of_params))\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(bbh_two_mass_samples))):\n",
    "\n",
    "    m1 = max(bbh_two_mass_samples[i][0], bbh_two_mass_samples[i][1])\n",
    "    m2 = min(bbh_two_mass_samples[i][0], bbh_two_mass_samples[i][1])\n",
    "\n",
    "    bbh_data_targets[i][0] = m1\n",
    "    bbh_data_targets[i][1] = m2\n",
    "\n",
    "    hp1, hc1 = get_td_waveform(approximant=\"SEOBNRv2\",                                \n",
    "                         mass1=m1,\n",
    "                         mass2=m2,\n",
    "                         delta_t=1.0/4096,\n",
    "                         f_lower=40)\n",
    "\n",
    "    \n",
    "    bbh_signal = TimeSeries.from_pycbc(hp1)\n",
    "    st1 = np.random.randint(0, 8)\n",
    "    bbh_signal.t0 = start_times_bbh[st1]\n",
    "    bbh_signal = (bbh_signal/(max(bbh_signal.max(), np.abs(bbh_signal.min()))))*0.2\n",
    "\n",
    "\n",
    "    # The color of the noise matches a PSD which you provide\n",
    "    flow = 30.0\n",
    "    delta_f = 1.0 / 16\n",
    "    flen = int(2048 / delta_f) + 1\n",
    "    psd = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, flow)\n",
    "\n",
    "    # Generate 4 seconds of noise at 4096 Hz\n",
    "    delta_t = 1.0 / 4096\n",
    "    tsamples = int(4 / delta_t)\n",
    "    noise = pycbc.noise.noise_from_psd(tsamples, delta_t, psd)\n",
    "\n",
    "    noise *= 1e21\n",
    "    noise *= 0.4\n",
    "    noise = TimeSeries.from_pycbc(noise)\n",
    "\n",
    "    data = noise.inject(bbh_signal)\n",
    "    data *= 1e-17\n",
    "\n",
    "    data.write(\"/Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/merged_bbh_noise_signal/merged_noise_signal_\"+str(i)+\".txt\")\n",
    "np.savetxt(\"/Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/val_Final_BBH_Merged_Noise_Signal_Targets_\"+str(no_of_params)+\"_parameters.csv\", bbh_data_targets, delimiter = \",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing BBH Noise + Signal Files: 100%|██████████| 2000/2000 [02:36<00:00, 12.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully saved merged BBH noise + signal data to: /Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/val_Final_BBH_Merged_Noise_Signal_Reduced_No_ABS_2_parameters.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Merging BBH Noise + Signal Templates into single csv file\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import chardet  # Auto-detect encoding\n",
    "\n",
    "# ✅ Define parameters\n",
    "no_of_params = 2  # Adjust as needed\n",
    "\n",
    "# ✅ Define directories\n",
    "base_dir = \"/Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/\"\n",
    "input_dir = os.path.join(base_dir, \"merged_bbh_noise_signal\")\n",
    "output_csv = os.path.join(base_dir, f\"val_Final_BBH_Merged_Noise_Signal_Reduced_No_ABS_{no_of_params}_parameters.csv\")\n",
    "\n",
    "# ✅ Ensure input directory exists\n",
    "if not os.path.exists(input_dir):\n",
    "    raise FileNotFoundError(f\"❌ Error: Directory '{input_dir}' not found!\")\n",
    "\n",
    "# ✅ Get list of valid files (only process .txt files)\n",
    "files = [f for f in os.listdir(input_dir) if f.endswith('.txt')]\n",
    "\n",
    "# ✅ Function to detect file encoding\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read(100000)  # Read a chunk of the file\n",
    "    return chardet.detect(raw_data)['encoding']\n",
    "\n",
    "# ✅ Open output CSV file\n",
    "with open(output_csv, 'w', newline='') as f:\n",
    "    cw = csv.writer(f)\n",
    "\n",
    "    for file in tqdm(files, desc=\"Processing BBH Noise + Signal Files\"):\n",
    "        file_path = os.path.join(input_dir, file)\n",
    "\n",
    "        try:\n",
    "            # ✅ Detect and use the correct encoding\n",
    "            encoding_type = detect_encoding(file_path)\n",
    "\n",
    "            # ✅ Read file with detected encoding\n",
    "            df = pd.read_csv(file_path, sep=r'\\s+', header=None, encoding=encoding_type, engine='python')\n",
    "\n",
    "            # ✅ Ensure file has at least 2 columns\n",
    "            if df.shape[1] < 2:\n",
    "                print(f\"❌ Error: {file} has only {df.shape[1]} column(s) - Possible formatting issue.\")\n",
    "                continue\n",
    "\n",
    "            # ✅ Convert to numeric format\n",
    "            df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # ✅ Write the second column\n",
    "            c = df.iloc[:, 1]  # Select second column\n",
    "            cw.writerow(c.dropna())  # Remove NaN values before writing\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file}: {e}\")\n",
    "\n",
    "print(f\"✅ Successfully saved merged BBH noise + signal data to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "########### BNS Data Generation ############\n",
    "############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Binary Mass Distributions for BNS\n"
     ]
    }
   ],
   "source": [
    "print(\"Generated Binary Mass Distributions for BNS\")\n",
    "bns_two_mass_distributions = distributions.Uniform(mass1=(1, 2),\n",
    "                                               mass2=(1, 2))\n",
    "\n",
    "bns_two_mass_samples = bns_two_mass_distributions.rvs(size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [06:20<00:00,  2.63it/s]\n"
     ]
    }
   ],
   "source": [
    "start_times_bns = [0, 0.5, 1, 1.5, 2, 2.5, 3]\n",
    "bns_data_targets = np.zeros((len(bns_two_mass_samples), no_of_params))\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(bns_two_mass_samples))):\n",
    "\n",
    "    m1 = max(bns_two_mass_samples[i][0], bns_two_mass_samples[i][1])\n",
    "    m2 = min(bns_two_mass_samples[i][0], bns_two_mass_samples[i][1])\n",
    "    \n",
    "    bns_data_targets[i][0] = m1\n",
    "    bns_data_targets[i][1] = m2\n",
    "\n",
    "    hp2, hc2 = get_td_waveform(approximant=\"IMRPhenomPv2_NRTidal\", \n",
    "                         mass1=m1,\n",
    "                         mass2=m2,\n",
    "                         delta_t=1.0/4096,\n",
    "                         f_lower=40)\n",
    "\n",
    "\n",
    "    # Extract the last 1 sec from the BNS signal\n",
    "    t = hp2.get_end_time()\n",
    "    hp2 = hp2.time_slice(t-1, t)\n",
    "\n",
    "    bns_signal = TimeSeries.from_pycbc(hp2)\n",
    "    st2 = np.random.randint(0, 7)\n",
    "    bns_signal.t0 = start_times_bns[st2]\n",
    "    bns_signal = bns_signal.taper()\n",
    "    bns_signal = (bns_signal/(max(bns_signal.max(), np.abs(bns_signal.min()))))*0.2\n",
    "\n",
    "    # The color of the noise matches a PSD which you provide\n",
    "    flow = 30.0\n",
    "    delta_f = 1.0 / 16\n",
    "    flen = int(2048 / delta_f) + 1\n",
    "    psd = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, flow)\n",
    "\n",
    "    # Generate 4 seconds of noise at 4096 Hz\n",
    "    delta_t = 1.0 / 4096\n",
    "    tsamples = int(4 / delta_t)\n",
    "    noise = pycbc.noise.noise_from_psd(tsamples, delta_t, psd)\n",
    "\n",
    "    noise *= 1e21\n",
    "    noise *= 0.4\n",
    "    noise = TimeSeries.from_pycbc(noise)\n",
    "\n",
    "    data = noise.inject(bns_signal)\n",
    "    data *= 1e-17\n",
    "\n",
    "    data.write(\"/Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/merged_bns_noise_signal/bns_merged_noise_signal_\"+str(i)+\".txt\")\n",
    "np.savetxt(\"/Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/val_Final_BNS_Merged_Noise_Signal_Targets_\"+str(no_of_params)+\"_parameters.csv\", bns_data_targets, delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing BNS Noise + Signal Files: 100%|██████████| 1000/1000 [00:46<00:00, 21.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully saved merged BNS noise + signal data to: /Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/val_Final_BNS_Merged_Noise_Signal_Reduced_No_ABS_2_parameters.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Merging BNS Noise + Signal Templates into single csv file\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ Define parameters\n",
    "no_of_params = 2  # Adjust as needed\n",
    "\n",
    "# ✅ Define directories\n",
    "base_dir = \"/Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/\"\n",
    "input_dir = os.path.join(base_dir, \"merged_bns_noise_signal\")\n",
    "output_csv = os.path.join(base_dir, f\"val_Final_BNS_Merged_Noise_Signal_Reduced_No_ABS_{no_of_params}_parameters.csv\")\n",
    "\n",
    "# ✅ Ensure input directory exists\n",
    "if not os.path.exists(input_dir):\n",
    "    raise FileNotFoundError(f\"❌ Error: Directory '{input_dir}' not found!\")\n",
    "\n",
    "# ✅ Get list of valid files (only process .txt files, exclude system files)\n",
    "files = [f for f in os.listdir(input_dir) if f.endswith('.txt')]\n",
    "\n",
    "# ✅ Open output CSV file\n",
    "with open(output_csv, 'w', newline='') as f:\n",
    "    cw = csv.writer(f)\n",
    "\n",
    "    for file in tqdm(files, desc=\"Processing BNS Noise + Signal Files\"):\n",
    "        file_path = os.path.join(input_dir, file)\n",
    "\n",
    "        try:\n",
    "            # ✅ Attempt to read with UTF-8 first, fallback to ISO-8859-1 if needed\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, sep=r'\\s+', header=None, encoding='utf-8', engine='python')\n",
    "            except UnicodeDecodeError:\n",
    "                df = pd.read_csv(file_path, sep=r'\\s+', header=None, encoding='ISO-8859-1', engine='python')\n",
    "\n",
    "            # ✅ Ensure file has at least 2 columns\n",
    "            if df.shape[1] < 2:\n",
    "                print(f\"❌ Error: {file} has only {df.shape[1]} column(s) - Possible formatting issue.\")\n",
    "                continue\n",
    "\n",
    "            # ✅ Convert to numeric format\n",
    "            df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # ✅ Write the second column\n",
    "            c = df.iloc[:, 1]  # Select second column\n",
    "            cw.writerow(c.dropna())  # Remove NaN values before writing\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file}: {e}\")\n",
    "\n",
    "print(f\"✅ Successfully saved merged BNS noise + signal data to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################\n",
    "########### Noise Data Generation ############\n",
    "##############################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Noise Files: 100%|██████████| 1000/1000 [00:36<00:00, 27.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully generated and saved 1000 noise files in: /Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/noise/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pycbc.noise\n",
    "import pycbc.psd\n",
    "from pycbc.types import TimeSeries\n",
    "\n",
    "# ✅ Define base directory for noise storage\n",
    "base_dir = \"/Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/noise/\"\n",
    "os.makedirs(base_dir, exist_ok=True)  # Ensure directory exists\n",
    "\n",
    "# ✅ Loop through `bbh_two_mass_samples` to generate noise\n",
    "for i in tqdm(range(len(bbh_two_mass_samples)), desc=\"Generating Noise Files\"):\n",
    "\n",
    "    # ✅ Generate noise PSD\n",
    "    flow = 30.0\n",
    "    delta_f = 1.0 / 16\n",
    "    flen = int(2048 / delta_f) + 1\n",
    "    psd = pycbc.psd.aLIGOZeroDetHighPower(flen, delta_f, flow)\n",
    "\n",
    "    # ✅ Generate 4 seconds of noise at 4096 Hz\n",
    "    delta_t = 1.0 / 4096\n",
    "    tsamples = int(4 / delta_t)\n",
    "    noise_array = pycbc.noise.noise_from_psd(tsamples, delta_t, psd)\n",
    "\n",
    "    # ✅ Corrected TimeSeries initialization (Fixes `.from_pycbc` issue)\n",
    "    noise = TimeSeries(noise_array, delta_t=delta_t)\n",
    "\n",
    "    # ✅ Scale noise\n",
    "    noise *= 1e21\n",
    "    noise *= 0.4\n",
    "    noise *= 1e-17  # Final scaling adjustment\n",
    "\n",
    "    # ✅ Save noise data as a properly formatted text file\n",
    "    output_path = os.path.join(base_dir, f\"noise_{i}.txt\")\n",
    "    np.savetxt(output_path, noise.numpy(), fmt=\"%.6e\")  # ✅ Save as a text file\n",
    "\n",
    "print(f\"✅ Successfully generated and saved {len(bbh_two_mass_samples)} noise files in: {base_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Regenerating ALL noise files to ensure correct formatting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Regenerating Noise Files: 100%|██████████| 1000/1000 [00:14<00:00, 68.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All noise files have been regenerated and are now correctly formatted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Noise Files: 100%|██████████| 1000/1000 [00:37<00:00, 26.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully saved merged noise data to: /Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/noise/val_Final_Merged_Noise_Reduced_No_ABS_2_parameters.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Merging Noise Templates into single csv file\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ✅ Define `no_of_params`\n",
    "no_of_params = 2  # Adjust based on dataset\n",
    "\n",
    "# ✅ Define directories\n",
    "base_dir = \"/Users/adamvanzant/Downloads/Gravitational-Wave-Detection-Using-Deep-Learning/raw_val_data_files/\"\n",
    "noise_dir = os.path.join(base_dir, \"noise\")\n",
    "output_csv = os.path.join(noise_dir, f\"val_Final_Merged_Noise_Reduced_No_ABS_{no_of_params}_parameters.csv\")\n",
    "\n",
    "# ✅ Ensure noise directory exists\n",
    "if not os.path.exists(noise_dir):\n",
    "    raise FileNotFoundError(f\"❌ Error: Directory '{noise_dir}' not found. Ensure noise files exist!\")\n",
    "\n",
    "# ✅ Get list of valid noise files (exclude system files like .DS_Store)\n",
    "files = [f for f in os.listdir(noise_dir) if f.endswith('.txt')]\n",
    "\n",
    "# ✅ Function to regenerate all noise files before processing\n",
    "def regenerate_noise_files():\n",
    "    \"\"\"\n",
    "    This function will regenerate ALL noise files in one go, \n",
    "    so we don't have to fix them mid-processing.\n",
    "    \"\"\"\n",
    "    print(\"🔄 Regenerating ALL noise files to ensure correct formatting...\")\n",
    "\n",
    "    for file in tqdm(files, desc=\"Regenerating Noise Files\"):\n",
    "        file_path = os.path.join(noise_dir, file)\n",
    "\n",
    "        # ✅ Generate correctly formatted noise data\n",
    "        tsamples = int(4 / (1.0 / 4096))  # 4 seconds of data at 4096 Hz\n",
    "        new_noise = np.column_stack((\n",
    "            np.linspace(0, tsamples-1, tsamples),  # Time index\n",
    "            np.random.normal(0, 1e-22, tsamples)  # Noise signal\n",
    "        ))\n",
    "\n",
    "        # ✅ Overwrite file with properly formatted data\n",
    "        np.savetxt(file_path, new_noise, fmt=\"%.6e\")\n",
    "\n",
    "    print(\"✅ All noise files have been regenerated and are now correctly formatted.\")\n",
    "\n",
    "# ✅ Run regeneration process before processing\n",
    "regenerate_noise_files()\n",
    "\n",
    "# ✅ Open output CSV file\n",
    "with open(output_csv, 'w', newline='') as f:\n",
    "    cw = csv.writer(f)\n",
    "\n",
    "    for file in tqdm(files, desc=\"Processing Noise Files\"):\n",
    "        file_path = os.path.join(noise_dir, file)\n",
    "\n",
    "        try:\n",
    "            # ✅ Read file with flexible separator to handle inconsistencies\n",
    "            df = pd.read_csv(file_path, sep=r'\\s+', header=None, engine='python')\n",
    "\n",
    "            # ✅ Convert to numeric format\n",
    "            df = df.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "            # ✅ Ensure at least 2 columns exist before selecting column 1\n",
    "            if df.shape[1] > 1:\n",
    "                c = df.iloc[:, 1]  # Select second column\n",
    "                cw.writerow(c.dropna())  # Remove NaN values before writing\n",
    "            else:\n",
    "                print(f\"❌ Skipping {file} - Still has only {df.shape[1]} column(s) after regeneration.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {file}: {e}\")\n",
    "\n",
    "print(f\"✅ Successfully saved merged noise data to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################################\n",
    "##################################################################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gw_env_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
